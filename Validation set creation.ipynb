{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.os.environ[\"PYSPARK_PYTHON\"]=\"python3\"\n",
    "findspark.os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"python3\"\n",
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark import SparkContext, SparkConf\n",
    "#import pydoop.hdfs as hdfs\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import StorageLevel\n",
    "\n",
    "import datetime\n",
    "import ujson as json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.5\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: PYSPARK_PYTHON\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"panel_sample\").config(\"PYSPARK_PYTHON\",\"python3\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.2.13:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://megatron.ccs.neu.edu:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>panel_sample</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f79f05558e0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECAHOSE PATTERNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-372a417627f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mschm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStructType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromJson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/nir/spark_stuff/decahose_schema.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mschm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ds\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStringType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdecahose_tweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/user/nir/decahose_tweets\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdecahose_tweets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateOrReplaceTempView\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"decahose_tweets\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "schm = StructType.fromJson(json.load(open(\"/home/nir/spark_stuff/decahose_schema.json\")))\n",
    "schm.add(\"ds\", StringType(), False, None)\n",
    "decahose_tweets = spark.read.json(\"/user/nir/decahose_tweets\", schema=schm)\n",
    "decahose_tweets.createOrReplaceTempView(\"decahose_tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -mkdir /user/etorf/decahose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "drwxr-xr-x   - etorf etorf          0 2021-09-30 11:47 /user/etorf/decahose/labeled_aug_to_nov\r\n",
      "drwxr-xr-x   - etorf etorf          0 2021-09-30 11:39 /user/etorf/decahose/matched_pattern_aug_to_nov\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/etorf/decahose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it took 4786.54461812973 seconds\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "#with SparkSession.builder.appName(\"panel_sample\").config(\"PYSPARK_PYTHON\",\"python3\").getOrCreate() as spark:\n",
    "schm = StructType.fromJson(json.load(open(\"/home/nir/spark_stuff/decahose_schema.json\")))\n",
    "schm.add(\"ds\", StringType(), False, None)\n",
    "decahose_tweets = spark.read.json(\"/user/nir/decahose_tweets\", schema=schm)\n",
    "decahose_tweets.filter(\"ds > '2020-07-31' AND ds <= '2020-11-31'\").createOrReplaceTempView(\"decahose_tweets_aug_to_nov\")\n",
    "t0 = time.time()\n",
    "\n",
    "after_filter = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "              user_id, user_screen_name, user_bio, ds\n",
    "    FROM\n",
    "              (select text, user.id as user_id, user.screen_name as user_screen_name, user.description as user_bio, ds from decahose_tweets_aug_to_nov)\n",
    "    WHERE \n",
    "               user_bio rlike '(?i)(I\\\\'?m|I am) a (guy\\man\\husband\\father\\dude)'\n",
    "            or user_bio rlike '(?i)(I\\\\'?m|I am) a (girl|mother|wife|woman)'\n",
    "            or user_bio rlike '(?i)wife of '\n",
    "            or user_bio rlike '(?i)husband of '\n",
    "            or user_bio rlike '(?i)mother (of|to) '\n",
    "            or user_bio rlike '(?i)father (of|to) '\n",
    "            or user_bio rlike '(?i)born in (\\\\\\\\d{4})'\n",
    "            or user_bio rlike '(?i)(\\\\\\\\d{2}) years old'\n",
    "            or user_bio rlike '(?i)(\\\\\\\\d{2}) y\\\\o (man|dude|guy)'\n",
    "            or user_bio rlike '(?i)(\\\\\\\\d{2}) y\\\\o (woman|lady|girl)'\n",
    "            or user_bio rlike '(?i)(^|, )(mother|wife|mom),'\n",
    "            or user_bio rlike '(?i)(^|, )(father|dad|husband),'\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "after_filter.write.save(\n",
    "        path=\"/user/etorf/decahose/matched_pattern_aug_to_nov\", format=\"json\", mode=\"append\", \n",
    "        partitionBy=[\"ds\"],\n",
    "        compression=\"bzip2\" )\n",
    "\n",
    "\n",
    "print(f\"it took {time.time() - t0} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "a = spark.read.json(\"/user/etorf/decahose/matched_pattern_aug_to_nov\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "916042"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.select([\"user_bio\", \"user_id\", \"user_screen_name\"]).dropDuplicates().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22515409"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it took 9.678255081176758 seconds\n"
     ]
    }
   ],
   "source": [
    "#with SparkSession.builder.appName(\"panel_sample\").config(\"PYSPARK_PYTHON\",\"python3\").getOrCreate() as spark:\n",
    "\n",
    "matched = spark.read.json(\"/user/etorf/decahose/matched_pattern_aug_to_nov\")\n",
    "matched_deduped = matched.select([\"user_bio\", \"user_id\", \"user_screen_name\"])\\\n",
    "                                    .dropDuplicates().createOrReplaceTempView(\"matched_deduped\")\n",
    "t0 = time.time()\n",
    "\n",
    "labeled = spark.sql(\"\"\"\n",
    "\t        SELECT \n",
    "                  user_id, user_screen_name, user_bio,\n",
    "                  CASE    WHEN user_bio rlike '(?i)born in (\\\\\\\\d{4})' THEN 'age_pattern_1'\n",
    "                          WHEN user_bio rlike '(?i)(\\\\\\\\d{2}) years old' THEN 'age_pattern_2'\n",
    "                          WHEN user_bio rlike '(?i)(\\\\\\\\d{2}) y\\\\o ' THEN 'age_pattern_3'\n",
    "                          ELSE 'unlabeled_age'\n",
    "                  END as age_pattern,\n",
    "                  CASE    WHEN user_bio rlike '(?i)born in (\\\\\\\\d{4})' THEN regexp_extract(user_bio, '(?i)born in (\\\\\\\\d{4})' ,1)\n",
    "                          WHEN user_bio rlike '(?i)(\\\\\\\\d{2}) years old' THEN regexp_extract(user_bio, '(?i)(\\\\\\\\d{2}) years old' ,1)\n",
    "                          WHEN user_bio rlike '(?i)(\\\\\\\\d{2}) y\\\\o ' THEN regexp_extract(user_bio, '(?i)(\\\\\\\\d{2}) y\\\\o ' ,1)\n",
    "                          ELSE 'unlabeled_age'\n",
    "                  END as age_label,\n",
    "                  CASE    WHEN user_bio rlike '(?i)(I\\\\'?m|I am) a (guy\\man\\husband\\father\\dude)' THEN 'gender_pattern_1'\n",
    "                          WHEN user_bio rlike '(?i)(I\\\\'?m|I am) a (girl|mother|wife|woman)' THEN 'gender_pattern_2'\n",
    "                          WHEN user_bio rlike '(?i)(\\\\\\\\d{2}) y\\\\o (woman|lady|girl)' THEN 'gender_pattern_3'\n",
    "                          WHEN user_bio rlike '(?i)(\\\\\\\\d{2}) y\\\\o (man|dude|guy)' THEN 'gender_pattern_4'\n",
    "                          WHEN user_bio rlike '(?i)(^|, )(mother|wife|mom),' THEN 'gender_pattern_5'\n",
    "                          WHEN user_bio rlike '(?i)(^|, )(father|dad|husband),' THEN 'gender_pattern_6'\n",
    "                          WHEN user_bio rlike '(?i)mother (of|to) ' THEN 'gender_pattern_7'\n",
    "                          WHEN user_bio rlike '(?i)father (of|to) ' THEN 'gender_pattern_8'\n",
    "                          WHEN user_bio rlike '(?i)wife of ' THEN 'gender_pattern_9'\n",
    "                          WHEN user_bio rlike '(?i)husband of ' THEN 'gender_pattern_10'\n",
    "                          ELSE 'unlabeled_gender'\n",
    "                  END as gender_pattern,\n",
    "                  CASE    WHEN user_bio rlike '(?i)(I\\\\'?m|I am) a (guy\\man\\husband\\father\\dude)' THEN 'MALE'\n",
    "                          WHEN user_bio rlike '(?i)(I\\\\'?m|I am) a (girl|mother|wife|woman)' THEN 'FEMALE'\n",
    "                          WHEN user_bio rlike '(?i)(\\\\\\\\d{2}) y\\\\o (woman|lady|girl)' THEN 'FEMALE'\n",
    "                          WHEN user_bio rlike '(?i)(\\\\\\\\d{2}) y\\\\o (man|dude|guy)' THEN 'MALE'\n",
    "                          WHEN user_bio rlike '(?i)(^|, )(mother|wife|mom),' THEN 'FEMALE'\n",
    "                          WHEN user_bio rlike '(?i)(^|, )(father|dad|husband),' THEN 'MALE'\n",
    "                          WHEN user_bio rlike '(?i)mother (of|to) ' THEN 'FEMALE'\n",
    "                          WHEN user_bio rlike '(?i)father (of|to) ' THEN 'MALE'\n",
    "                          WHEN user_bio rlike '(?i)wife of ' THEN 'FEMALE'\n",
    "                          WHEN user_bio rlike '(?i)husband of ' THEN 'MALE'\n",
    "                          ELSE 'unlabeled_gender'\n",
    "                  END as gender_label\n",
    "\n",
    "        FROM      matched_deduped\n",
    "    \"\"\")\n",
    "\n",
    "\n",
    "labeled.write.save(\n",
    "            path=\"/user/etorf/decahose/labeled_aug_to_nov\", format=\"json\", mode=\"append\", \n",
    "            compression=\"bzip2\" )\n",
    "\n",
    "print(f\"it took {time.time() - t0} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = spark.read.json(\"/user/etorf/decahose/labeled_aug_to_nov\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+\n",
      "|  gender_pattern| count|\n",
      "+----------------+------+\n",
      "|gender_pattern_9| 18159|\n",
      "|gender_pattern_3|  1030|\n",
      "|gender_pattern_7|144019|\n",
      "|gender_pattern_5|200886|\n",
      "|gender_pattern_2| 22178|\n",
      "+----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a.filter(\"gender_label = 'FEMALE'\").groupby(\"gender_pattern\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------+\n",
      "|   gender_pattern| count|\n",
      "+-----------------+------+\n",
      "| gender_pattern_8|146582|\n",
      "|gender_pattern_10|  8666|\n",
      "| gender_pattern_4|   752|\n",
      "| gender_pattern_6|250770|\n",
      "+-----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a.filter(\"gender_label = 'MALE'\").groupby(\"gender_pattern\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.filter(\"gender_label = 'FEMALE' AND gender_pattern='gender_pattern_7'\").select('user_bio').show(40,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_185619/422651858.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/user/etorf/decahose/labeled_may_to_dec\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "a = spark.read.json(\"/user/etorf/decahose/labeled_may_to_dec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+\n",
      "|  gender_pattern|count|\n",
      "+----------------+-----+\n",
      "|gender_pattern_3| 1091|\n",
      "|gender_pattern_7|36973|\n",
      "|gender_pattern_5|    5|\n",
      "|gender_pattern_2|    8|\n",
      "+----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a.filter(\"gender_label = 'FEMALE'\").groupby(\"gender_pattern\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+\n",
      "|  gender_pattern|count|\n",
      "+----------------+-----+\n",
      "|gender_pattern_4|  636|\n",
      "+----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a.filter(\"gender_label = 'MALE'\").groupby(\"gender_pattern\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 49:==================================================>  (382 + 18) / 400]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+\n",
      "|  age_pattern|  count|\n",
      "+-------------+-------+\n",
      "|age_pattern_1|   9630|\n",
      "|age_pattern_2| 139832|\n",
      "|age_pattern_3|   2237|\n",
      "|unlabeled_age|1680385|\n",
      "+-------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a.groupby(\"age_pattern\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 59:=================================================>   (374 + 26) / 400]\r",
      "\r",
      "[Stage 59:===================================================> (389 + 11) / 400]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|age_label|count|\n",
      "+---------+-----+\n",
      "|       00|  732|\n",
      "|       01|   13|\n",
      "|     0121|    1|\n",
      "|       02|   12|\n",
      "|       03|   17|\n",
      "|       04|   13|\n",
      "|       05|    3|\n",
      "|       06|    3|\n",
      "|     0606|    1|\n",
      "|       07|    8|\n",
      "|       08|   16|\n",
      "|       09|   13|\n",
      "|       10|  856|\n",
      "|     1000|    3|\n",
      "|     1001|    1|\n",
      "|     1005|    1|\n",
      "|     1028|    1|\n",
      "|     1066|    2|\n",
      "|     1095|    2|\n",
      "|       11|  970|\n",
      "|     1111|    2|\n",
      "|     1180|    1|\n",
      "|       12| 1946|\n",
      "|     1200|    1|\n",
      "|     1215|    1|\n",
      "|     1235|    2|\n",
      "|     1246|    1|\n",
      "|     1290|    1|\n",
      "|       13| 5086|\n",
      "|     1305|    1|\n",
      "|     1312|    1|\n",
      "|     1349|    1|\n",
      "|     1353|    1|\n",
      "|     1370|    1|\n",
      "|     1375|    1|\n",
      "|     1380|    1|\n",
      "|     1392|    1|\n",
      "|       14| 6712|\n",
      "|     1413|    1|\n",
      "|     1420|    1|\n",
      "|     1421|    2|\n",
      "|     1422|    1|\n",
      "|     1428|    1|\n",
      "|     1431|    1|\n",
      "|     1438|    2|\n",
      "|     1452|    1|\n",
      "|     1453|    1|\n",
      "|     1460|    1|\n",
      "|     1474|    5|\n",
      "|     1485|    6|\n",
      "|     1488|    2|\n",
      "|       15| 7504|\n",
      "|     1500|    2|\n",
      "|     1509|    1|\n",
      "|     1518|    1|\n",
      "|     1521|    3|\n",
      "|     1536|    1|\n",
      "|     1551|    2|\n",
      "|     1562|    1|\n",
      "|     1564|    1|\n",
      "|     1566|    1|\n",
      "|     1568|    1|\n",
      "|     1577|    1|\n",
      "|     1582|    1|\n",
      "|     1588|    1|\n",
      "|       16| 8137|\n",
      "|     1600|    1|\n",
      "|     1602|    2|\n",
      "|     1620|    2|\n",
      "|     1632|    2|\n",
      "|     1642|    1|\n",
      "|     1643|    1|\n",
      "|     1660|    1|\n",
      "|     1667|    1|\n",
      "|     1670|    4|\n",
      "|     1678|    4|\n",
      "|     1685|    1|\n",
      "|       17| 7907|\n",
      "|     1700|    1|\n",
      "|     1701|    1|\n",
      "|     1703|    1|\n",
      "|     1704|    2|\n",
      "|     1706|    2|\n",
      "|     1723|    2|\n",
      "|     1739|    1|\n",
      "|     1740|    1|\n",
      "|     1753|    1|\n",
      "|     1755|    7|\n",
      "|     1760|    1|\n",
      "|     1767|    1|\n",
      "|     1775|    2|\n",
      "|     1776|    4|\n",
      "|     1778|    2|\n",
      "|     1783|    1|\n",
      "|     1784|    1|\n",
      "|     1786|    1|\n",
      "|     1787|    1|\n",
      "|     1788|    1|\n",
      "|     1789|    3|\n",
      "|     1791|    1|\n",
      "+---------+-----+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "a.groupby(\"age_label\").count().orderBy(\"age_label\").show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "labled_set = spark.read.json(\"/user/etorf/decahose/labeled_aug_to_nov\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "labled_set.createOrReplaceTempView(\"labled_set\")\n",
    "\n",
    "def validate_and_group_age(age_label):\n",
    "    if age_label == 'unlabeled_age':\n",
    "        return 'unlabeled_age'\n",
    "    if len(age_label) == 4: # year\n",
    "        year = int(age_label)\n",
    "        if (year < 1923 or year > 2013):\n",
    "            return None #filter out of range\n",
    "        age = 2021 - year\n",
    "    else: #2 גdigit age\n",
    "        age = int(age_label)\n",
    "        if (age < 8 or age >= 99):\n",
    "            return None #filter out of range\n",
    "    if age <= 18:\n",
    "        return '<=18'\n",
    "    if age < 30:\n",
    "        return '(18-30)'\n",
    "    if age < 40:\n",
    "        return '[30-40)'\n",
    "    else:\n",
    "        return '[40-99)'\n",
    "    \n",
    "spark.udf.register(\"validate_and_group_age\", validate_and_group_age, StringType())\n",
    "\n",
    "grouped_age = spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM (\n",
    "        SELECT \n",
    "            validate_and_group_age(age_label)      as age_group,\n",
    "            *\n",
    "        FROM \n",
    "            labled_set\n",
    "        ) a\n",
    "    WHERE age_group is not null and age_group <> 'unlabeled_age' \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|age_group|count|\n",
      "+---------+-----+\n",
      "|  [40-99)| 7282|\n",
      "|  [30-40)| 8412|\n",
      "|     <=18|52029|\n",
      "|  (18-30)|82575|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grouped_age.groupby(\"age_group\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-------------+----------------+----------------+--------------------+-------------------+----------------+\n",
      "|age_group|age_label|  age_pattern|    gender_label|  gender_pattern|            user_bio|            user_id|user_screen_name|\n",
      "+---------+---------+-------------+----------------+----------------+--------------------+-------------------+----------------+\n",
      "|  (18-30)|       25|age_pattern_2|unlabeled_gender|unlabeled_gender|25 years old, GSU...|         1605137881|         DrPWN13|\n",
      "|  (18-30)|     2002|age_pattern_1|unlabeled_gender|unlabeled_gender|-Tina, Nora, Dais...|1124801469402603520|          fefxri|\n",
      "|  (18-30)|       21|age_pattern_2|unlabeled_gender|unlabeled_gender|-Italian porn act...|1207931183499300864|     Maryjane_nm|\n",
      "|  (18-30)|       19|age_pattern_2|unlabeled_gender|unlabeled_gender|I Love min yoongi...| 883870766609178624|   YGeilmioamore|\n",
      "+---------+---------+-------------+----------------+----------------+--------------------+-------------------+----------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grouped_age.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "grouped_age.select(['user_id', 'age_group', 'age_label', 'age_pattern']).orderBy(rand()).repartition(1).write.save(\n",
    "            path=\"/user/etorf/validation_set_age_csv\", format=\"csv\"\n",
    "            , header='True'\n",
    "            , sep='\\t'\n",
    "            , mode='overwrite'\n",
    "            , compression=\"gzip\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------------+------+\n",
      "|  age_pattern|   gender_pattern| count|\n",
      "+-------------+-----------------+------+\n",
      "|age_pattern_1| unlabeled_gender|  8978|\n",
      "|age_pattern_2| gender_pattern_9|    30|\n",
      "|age_pattern_3| gender_pattern_5|     9|\n",
      "|age_pattern_2| gender_pattern_4|     1|\n",
      "|age_pattern_3| gender_pattern_2|    89|\n",
      "|age_pattern_3| gender_pattern_8|    46|\n",
      "|age_pattern_1| gender_pattern_2|    10|\n",
      "|age_pattern_3| gender_pattern_4|   747|\n",
      "|age_pattern_2| gender_pattern_8|   620|\n",
      "|age_pattern_1| gender_pattern_8|    50|\n",
      "|age_pattern_1| gender_pattern_9|     7|\n",
      "|age_pattern_2|gender_pattern_10|    13|\n",
      "|age_pattern_3|gender_pattern_10|     2|\n",
      "|age_pattern_1| gender_pattern_4|     2|\n",
      "|age_pattern_2| gender_pattern_6|    51|\n",
      "|age_pattern_1| gender_pattern_6|    10|\n",
      "|age_pattern_3| gender_pattern_7|    64|\n",
      "|age_pattern_3| unlabeled_gender|   226|\n",
      "|age_pattern_1| gender_pattern_7|    17|\n",
      "|age_pattern_2| gender_pattern_5|    48|\n",
      "|age_pattern_2| gender_pattern_2|   261|\n",
      "|age_pattern_1| gender_pattern_5|     2|\n",
      "|age_pattern_3| gender_pattern_3|  1030|\n",
      "|age_pattern_3| gender_pattern_9|     2|\n",
      "|age_pattern_3| gender_pattern_6|    13|\n",
      "|age_pattern_2| unlabeled_gender|137504|\n",
      "|age_pattern_2| gender_pattern_7|   466|\n",
      "+-------------+-----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grouped_age.groupby([\"age_pattern\",\"gender_pattern\"]).count().show(50) #check overlap between datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+------------+----------------+--------------------+-------------------+----------------+\n",
      "|    age_label|  age_pattern|gender_label|  gender_pattern|            user_bio|            user_id|user_screen_name|\n",
      "+-------------+-------------+------------+----------------+--------------------+-------------------+----------------+\n",
      "|unlabeled_age|unlabeled_age|      FEMALE|gender_pattern_2|I am a wife, mom,...|1314042905724559362|     THEFLY20204|\n",
      "|unlabeled_age|unlabeled_age|        MALE|gender_pattern_6|Husband, father, ...|           30063549|   ConstableCurt|\n",
      "+-------------+-------------+------------+----------------+--------------------+-------------------+----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labled_set.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "labled_set.filter(\"gender_pattern <> 'unlabeled_gender'\")\\\n",
    "            .select(['user_id', 'gender_pattern', 'gender_label']).orderBy(rand()).repartition(1).write.save(\n",
    "            path=\"/user/etorf/validation_set_gender_csv\", format=\"csv\"\n",
    "            , header='True'\n",
    "            , sep='\\t'\n",
    "            , compression=\"gzip\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+--------------------+---------+\n",
      "|                    text|    retweeted_status|retweeted|\n",
      "+------------------------+--------------------+---------+\n",
      "|    jaja https://t.co...|                null|    false|\n",
      "|    Congratulations o...|                null|    false|\n",
      "|    RT @Maximus_4EVR:...|{null, null, Mon ...|    false|\n",
      "|    RT @ItsDeanBlunde...|{null, null, Mon ...|    false|\n",
      "|    RT @miyaplanners:...|{null, null, Fri ...|    false|\n",
      "|               @idvswe .|                null|    false|\n",
      "|    RT @alqaradawy: ن...|{null, null, Sun ...|    false|\n",
      "|    @starryscarlette ...|                null|    false|\n",
      "|    RT @dannu34: Buen...|{null, null, Sun ...|    false|\n",
      "|    RT @txemita: El G...|{null, null, Mon ...|    false|\n",
      "|    RT @GoodHeartWinz...|{null, null, Sun ...|    false|\n",
      "|    Mamãe vai me por ...|                null|    false|\n",
      "|    RT @inlemidnight:...|{null, null, Mon ...|    false|\n",
      "|    RT @PrettyGirlRaj...|{null, null, Mon ...|    false|\n",
      "|    RT @Ahnonymouz: P...|{null, null, Sun ...|    false|\n",
      "|3E8D5A52 :参戦ID\n",
      "参加...|                null|    false|\n",
      "|    @TTV_Djmas23 So a...|                null|    false|\n",
      "|    @access_design90 ...|                null|    false|\n",
      "|    bu neee OIFASHODG...|                null|    false|\n",
      "|    @elmostrador Que ...|                null|    false|\n",
      "+------------------------+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schm = StructType.fromJson(json.load(open(\"/home/nir/spark_stuff/decahose_schema.json\")))\n",
    "schm.add(\"ds\", StringType(), False, None)\n",
    "decahose_tweets = spark.read.json(\"/user/nir/decahose_tweets\", schema=schm)\n",
    "decahose_tweets.filter(\"ds = '2020-06-31'\").createOrReplaceTempView(\"decahose_sample\")\n",
    "t0 = time.time()\n",
    "\n",
    "decahose_tweets.select(['text', 'retweeted_status', 'retweeted']).show(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "etorf",
   "language": "python",
   "name": "etorf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
